# üéÆ Clash Royale Deck Recommendation usando GraphSAGE

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.6+-red.svg)
![PyTorch Geometric](https://img.shields.io/badge/PyG-2.7.0-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

Sistema de recomendaci√≥n de mazos para Clash Royale basado en **Graph Neural Networks (GraphSAGE)** que, dado un mazo incompleto de 6 cartas, recomienda las 2 cartas faltantes utilizando sinergias aprendidas de decks de jugadores profesionales.

---

## üìã Contenido del Repositorio

```
ClashRoyalGNN/
‚îú‚îÄ‚îÄ models_transfer/             # Modelos de transfer learning (.pt) y historial
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pt
‚îÇ   ‚îú‚îÄ‚îÄ training_history.json
‚îÇ   ‚îî‚îÄ‚îÄ training_history.csv
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ 01-raw/                  # Datos crudos del API de Clash Royale
‚îÇ   ‚îú‚îÄ‚îÄ 02-preprocessed/         # Matriz de co-ocurrencia preprocesada
‚îÇ   ‚îú‚îÄ‚îÄ 03-features/             # Caracter√≠sticas del grafo y ejemplos de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ 04-predictions/          # Predicciones del modelo
‚îú‚îÄ‚îÄ entrypoint/
‚îÇ   ‚îú‚îÄ‚îÄ train_transfer_learning.py  # ‚≠ê ENTRYPOINT PRINCIPAL - Transfer Learning
‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Entrenamiento desde cero (no usado en este proyecto)
‚îÇ   ‚îú‚îÄ‚îÄ inference.py             # Script de inferencia/predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ compare_models.py        # Comparaci√≥n de modelos
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pretrained_sage.py   # ‚≠ê GraphSAGE con Transfer Learning (USADO)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graphsage_model.py   # Modelo GraphSAGE base
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gnn_model.py         # Modelo GCN base
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_pipeline.py      # Pipeline de entrenamiento (shared)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_eng_pipeline.py   # Pipeline de ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference_pipeline.py     # Pipeline de inferencia
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Utilidades (config, device, logging)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml              # Configuraci√≥n del modelo y transfer learning
‚îú‚îÄ‚îÄ Dockerfile                   # Docker para AMD/Strix Halo (Linux + ROCm)
‚îú‚îÄ‚îÄ docker-compose.yml           # Docker Compose para AMD GPUs
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                    # Este archivo
```

---

## üéØ Motivaci√≥n del Proyecto

### ¬øPor qu√© Graph Neural Networks?

En Clash Royale, las **sinergias entre cartas** son m√°s importantes que las cartas individuales. Un mazo exitoso no es simplemente una colecci√≥n de cartas poderosas, sino un conjunto de cartas que trabajan bien juntas.

Los sistemas de recomendaci√≥n tradicionales tratan las cartas como items independientes, ignorando estas relaciones complejas. Las **Graph Neural Networks (GNNs)** son ideales para este problema porque:

1. **Modelado natural de relaciones**: Las cartas forman un grafo donde las aristas representan sinergias aprendidas de decks profesionales.
2. **Captura de patrones complejos**: Las GNNs aprenden patrones de co-ocurrencia, sinergias ofensivas/defensivas, y composiciones meta.
3. **Propagaci√≥n de informaci√≥n**: El mecanismo de "message passing" permite que cada carta "aprenda" de sus vecinos en el grafo.

### ¬øPor qu√© GraphSAGE?

Comparado con otras arquitecturas de GNN:

| Arquitectura           | Ventajas                                                                                                        | Desventajas                                        |
| ---------------------- | --------------------------------------------------------------------------------------------------------------- | -------------------------------------------------- |
| **GCN**          | Simple, r√°pido, bien establecido                                                                               | Usa todos los vecinos (no escala), pesos uniformes |
| **GAT**          | Attention mechanism, m√°s expresivo                                                                             | M√°s lento, m√°s par√°metros, puede sobreajustar   |
| **GIN**          | Muy expresivo, inyectivo                                                                                        | Complejo, dif√≠cil de entrenar                     |
| **GraphSAGE** ‚úÖ | **Muestreo de vecinos** (escalable), **agregaci√≥n aprendida**, mejor para relaciones heterog√©neas | Ligeramente m√°s lento que GCN                     |

**GraphSAGE fue elegido porque:**

- ‚úÖ **Neighbor Sampling**: M√°s escalable que GCN (importante si el grafo crece)
- ‚úÖ **Learned Aggregation**: Captura mejor las sinergias heterog√©neas (soporte, defensa, win conditions)
- ‚úÖ **Inductivo**: Puede generalizar a cartas nuevas sin reentrenar desde cero
- ‚úÖ **Balance**: M√°s expresivo que GCN, m√°s eficiente que GAT

---

## üï∏Ô∏è Arquitectura del Grafo

### Construcci√≥n del Grafo

El grafo se construye a partir de **datos reales de jugadores top** (clanes con score ‚â• 99,000):

#### Nodos (Vertices)

- **Cantidad**: 110 cartas de Clash Royale
- **Representaci√≥n**: Cada carta es un nodo en el grafo
- **Features por nodo**: 5 caracter√≠sticas num√©ricas + 1 indicador binario

#### Aristas (Edges)

- **Tipo**: Co-ocurrencia en decks profesionales
- **Peso**: Frecuencia de aparici√≥n conjunta
- **Threshold**: Solo se crean aristas si dos cartas aparecen juntas ‚â• 5 veces
- **Direcci√≥n**: No dirigidas (sim√©tricas)
- **Cantidad**: ~7,232 aristas en el grafo final

**Ejemplo**: Si "Hog Rider" y "Fireball" aparecen juntas en 150 decks, se crea una arista con peso 150.

#### Features de Nodo

Cada carta tiene 6 features:

| Feature               | Descripci√≥n                | Tipo                     | Rango                                 |
| --------------------- | --------------------------- | ------------------------ | ------------------------------------- |
| `id`                | ID √∫nico de la carta       | Num√©rico (normalizado)  | [0, 1]                                |
| `elixirCost`        | Costo de elixir             | Num√©rico (normalizado)  | 1-10 elixir                           |
| `rarity`            | Rareza de la carta          | Categ√≥rico ‚Üí Num√©rico | 0=Common, 1=Rare, 2=Epic, 3=Legendary |
| `maxLevel`          | Nivel m√°ximo               | Num√©rico (normalizado)  | 6-14                                  |
| `maxEvolutionLevel` | Nivel de evoluci√≥n m√°ximo | Num√©rico (normalizado)  | 0-1                                   |
| `input_indicator`   | ¬øEst√° en el input?        | Binario                  | 0 o 1                                 |

**Normalizaci√≥n**: Todas las features se normalizan usando **estandarizaci√≥n** (media=0, std=1):

```
x_normalized = (x - mean) / std
```

Esto asegura que todas las features tengan la misma escala y el modelo converja m√°s r√°pido.

---

## üß† Arquitectura del Modelo (GraphSAGE)

### Dise√±o de Capas

```
Input (6 features)
    ‚Üì
SAGEConv Layer 1: 6 ‚Üí 512 (mean aggregation)
    ‚Üì ReLU + Dropout(0.4)
SAGEConv Layer 2: 512 ‚Üí 256 (mean aggregation)
    ‚Üì ReLU + Dropout(0.3)
SAGEConv Layer 3: 256 ‚Üí 128 (mean aggregation)
    ‚Üì ReLU + Dropout(0.2)
SAGEConv Layer 4: 128 ‚Üí 64 (mean aggregation)
    ‚Üì ReLU + Dropout(0.1)
Mean Pooling (agregaci√≥n de nodos)
    ‚Üì
Linear Output Layer: 64 ‚Üí 110 (probabilidad por carta)
    ‚Üì
Softmax
```

### Componentes Clave

#### 1. Capas SAGEConv (GraphSAGE Convolutional Layers)

Cada capa GraphSAGE realiza:

```python
h_i^(k) = œÉ(W ¬∑ CONCAT(h_i^(k-1), AGG({h_j^(k-1) : j ‚àà N(i)})))
```

Donde:

- `h_i^(k)`: Embedding del nodo `i` en la capa `k`
- `œÉ`: Funci√≥n de activaci√≥n (ReLU)
- `W`: Matriz de pesos aprendibles
- `CONCAT`: Concatenaci√≥n de features propias y agregadas
- `AGG`: Funci√≥n de agregaci√≥n (en nuestro caso, **mean**)
- `N(i)`: Vecinos del nodo `i`

#### 2. Agregador: Mean Aggregation

**¬øPor qu√© Mean?**

- ‚úÖ **Additive synergies**: Las sinergias en Clash Royale son t√≠picamente aditivas
- ‚úÖ **Estabilidad**: Menos sensible a outliers que `max`
- ‚úÖ **Eficiencia**: M√°s r√°pido que `lstm` aggregator
- ‚úÖ **Interpretable**: El promedio de vecinos tiene sentido sem√°ntico

Otras opciones disponibles (no usadas):

- `max`: Max pooling (para features dominantes)
- `lstm`: LSTM-based aggregation (m√°s expresivo pero m√°s lento)

#### 3. Funciones de Activaci√≥n

- **ReLU** (Rectified Linear Unit): `f(x) = max(0, x)`
  - Introduce no-linealidad
  - Previene vanishing gradients
  - Computacionalmente eficiente

#### 4. Regularizaci√≥n

**Dropout** con tasas decrecientes:

- Layer 1: 40% dropout
- Layer 2: 30% dropout
- Layer 3: 20% dropout
- Layer 4: 10% dropout

**Rationale**: Las capas tempranas aprenden features m√°s generales (mayor dropout), las capas finales aprenden features espec√≠ficas (menor dropout).

**Gradient Clipping**: Norma m√°xima = 1.0

- Previene exploding gradients
- Estabiliza el entrenamiento

#### 5. Pooling (Readout)

**Mean Pooling** sobre todos los nodos:

```python
h_graph = MEAN({h_i^(L) : i ‚àà V})
```

Esto produce una representaci√≥n de todo el grafo (deck) que captura informaci√≥n de todas las cartas.

#### 6. Capa de Salida (MLP)

Capa lineal final que mapea el embedding del grafo a probabilidades:

```python
output = Linear(64 ‚Üí 110) + Softmax
```

Cada salida representa la probabilidad de que una carta espec√≠fica deba estar en el deck.

---

## üî¢ C√°lculo del N√∫mero de Par√°metros

### F√≥rmula para SAGEConv

En GraphSAGE con concatenaci√≥n, cada capa tiene:

```
params = (in_features + in_features) √ó out_features + out_features
```

Porque SAGEConv concatena las features del nodo con las features agregadas de sus vecinos.

### Desglose por Capa

| Capa                    | Input ‚Üí Output | Par√°metros       | C√°lculo                       |
| ----------------------- | --------------- | ----------------- | ------------------------------ |
| **SAGEConv 1**    | 6 ‚Üí 512        | **6,656**   | (6+6)√ó512 + 512 = 6,656       |
| **SAGEConv 2**    | 512 ‚Üí 256      | **262,400** | (512+512)√ó256 + 256 = 262,400 |
| **SAGEConv 3**    | 256 ‚Üí 128      | **65,664**  | (256+256)√ó128 + 128 = 65,664  |
| **SAGEConv 4**    | 128 ‚Üí 64       | **16,448**  | (128+128)√ó64 + 64 = 16,448    |
| **Linear Output** | 64 ‚Üí 110       | **7,150**   | 64√ó110 + 110 = 7,150          |
| **Total**         |                 | **358,318** |                                |

### Comparaci√≥n con GCN

| Modelo    | Par√°metros       | Diferencia                   |
| --------- | ----------------- | ---------------------------- |
| GCN       | ~320,000          | Baseline                     |
| GraphSAGE | **358,318** | +12% (por la concatenaci√≥n) |

El aumento es razonable considerando la mayor expresividad de GraphSAGE.

---

## üîÑ Transfer Learning con GraphSAGE

Este proyecto utiliza **Transfer Learning** con entrenamiento por etapas (staged training) para mejorar la convergencia y estabilidad del modelo.

### Arquitectura del Modelo de Transfer Learning

```
Card Features (6-dim)
    ‚Üì
Feature Adapter: 6 ‚Üí 128-dim
    ‚îú‚îÄ Linear Layer: 6 ‚Üí 64
    ‚îú‚îÄ ReLU + Dropout(0.4)
    ‚îî‚îÄ Linear Layer: 64 ‚Üí 128 + LayerNorm
    ‚Üì
Pretrained GraphSAGE Encoder: 128 ‚Üí 256 ‚Üí 128
    ‚îú‚îÄ SAGEConv Layer 1: 128 ‚Üí 256 (frozen en Stage 1)
    ‚îú‚îÄ ReLU + Dropout(0.3)
    ‚îú‚îÄ SAGEConv Layer 2: 256 ‚Üí 128 (frozen en Stage 1)
    ‚îî‚îÄ ReLU + Dropout(0.2)
    ‚Üì
Fine-tuning Layers: 128 ‚Üí 64
    ‚îú‚îÄ SAGEConv Layer: 128 ‚Üí 64 (task-specific)
    ‚îî‚îÄ ReLU + Dropout(0.1)
    ‚Üì
Task Head (Output Layer): 64 ‚Üí 110 cards
    ‚îî‚îÄ Linear + Softmax
```

#### Componentes del Modelo

| Componente | Entrada ‚Üí Salida | Funci√≥n | Par√°metros |
|------------|------------------|---------|------------|
| **Feature Adapter** | 6 ‚Üí 128 | Proyecta features de cartas a dimensi√≥n pretrained | ~8,000 |
| **Pretrained Encoder** | 128 ‚Üí 256 ‚Üí 128 | Extrae representaciones generales (GraphSAGE) | ~98,000 |
| **Fine-tuning Layer** | 128 ‚Üí 64 | Capa espec√≠fica del task | ~16,000 |
| **Task Head** | 64 ‚Üí 110 | Predicci√≥n final de cartas | ~7,000 |
| **Total** | - | - | **~164,078** |

### Staged Training (Entrenamiento por Etapas)

El transfer learning se realiza en **3 stages** con freezing/unfreezing progresivo:

#### **Stage 1: Adapter Training** (5 √©pocas, LR=0.01)

```python
Capas Entrenables:
  ‚úÖ Feature Adapter
  ‚úÖ Task Head (Output Layer)

Capas Congeladas:
  ‚ùÑÔ∏è Pretrained Encoder (frozen)
  ‚ùÑÔ∏è Fine-tuning Layer (frozen)

Par√°metros Entrenables: ~15,000 (9% del total)
```

**Objetivo**: Entrenar el adapter para proyectar features de cartas al espacio pretrained sin alterar el encoder.

#### **Stage 2: Partial Fine-tuning** (10 √©pocas, LR=0.005)

```python
Capas Entrenables:
  ‚úÖ Feature Adapter
  ‚úÖ Pretrained Encoder - √öltimas 2 capas (unfrozen)
  ‚úÖ Fine-tuning Layer
  ‚úÖ Task Head

Capas Congeladas:
  ‚ùÑÔ∏è Pretrained Encoder - Primera capa (frozen)

Par√°metros Entrenables: ~120,000 (73% del total)
```

**Objetivo**: Ajustar las capas superiores del encoder y las capas task-specific.

#### **Stage 3: Full Fine-tuning** (10 √©pocas, LR=0.001)

```python
Capas Entrenables:
  ‚úÖ Feature Adapter
  ‚úÖ Pretrained Encoder - Todas las capas (unfrozen)
  ‚úÖ Fine-tuning Layer
  ‚úÖ Task Head

Par√°metros Entrenables: ~164,078 (100% del total)
```

**Objetivo**: Fine-tuning completo de todo el modelo con LR muy bajo para no destruir lo aprendido.

### ¬øPor qu√© Transfer Learning?

| Aspecto | Entrenamiento desde Cero | Transfer Learning ‚úÖ |
|---------|-------------------------|---------------------|
| **Convergencia** | Lenta (~20-30 √©pocas) | R√°pida (~13-25 √©pocas totales) |
| **Estabilidad** | Puede ser err√°tica | M√°s estable por staged approach |
| **Val Loss Inicial** | ~4.1 | ~3.9 (mejor inicio) |
| **Val Loss Final** | ~3.35 | ~3.20 (mejor resultado) |
| **Risk de Overfitting** | Alto | Bajo (freezing progresivo) |
| **Tiempo Total** | ~2.5 horas (10 √©pocas) | ~6-8 horas (25 √©pocas) pero mejor resultado |

### Ventajas del Staged Training

1. **Convergencia m√°s r√°pida**: El adapter aprende la proyecci√≥n sin alterar el encoder pretrained
2. **Mayor estabilidad**: El freezing previene cambios dr√°sticos en las primeras √©pocas
3. **Menor overfitting**: El modelo no puede "memorizar" tan f√°cilmente
4. **Learning rates adaptativos**: Cada stage usa un LR apropiado para su objetivo
5. **Mejor generalizaci√≥n**: El encoder mantiene representaciones generales √∫tiles

### Configuraci√≥n de Transfer Learning

La configuraci√≥n se define en `config/config.yaml`:

```yaml
training:
  lr: 0.01  # Learning rate base

  transfer_learning:
    stage1_epochs: 5   # Adapter training
    stage2_epochs: 10  # Partial fine-tuning
    stage3_epochs: 10  # Full fine-tuning
    stage2_lr_factor: 0.5   # LR Stage 2 = 0.01 √ó 0.5 = 0.005
    stage3_lr_factor: 0.1   # LR Stage 3 = 0.01 √ó 0.1 = 0.001
```

### C√°lculo de Par√°metros por Stage

| Stage | Adapter | Encoder | Finetune | Task Head | Total Entrenables | % |
|-------|---------|---------|----------|-----------|-------------------|---|
| **Stage 1** | ‚úÖ 8K | ‚ùÑÔ∏è 0 | ‚ùÑÔ∏è 0 | ‚úÖ 7K | **~15K** | 9% |
| **Stage 2** | ‚úÖ 8K | ‚úÖ 90K | ‚úÖ 16K | ‚úÖ 7K | **~121K** | 73% |
| **Stage 3** | ‚úÖ 8K | ‚úÖ 98K | ‚úÖ 16K | ‚úÖ 7K | **~164K** | 100% |

---

## üìä Dataset

### Fuente de Datos

**API de Clash Royale Oficial**: `https://api.clashroyale.com/v1`

Datos obtenidos de:

1. **Top Clans**: Clanes con score ‚â• 99,000
2. **Battle Logs**: Historial de batallas de jugadores en esos clanes
3. **Decks Profesionales**: Mazos de 8 cartas usados en partidas competitivas

### Estad√≠sticas del Dataset

| M√©trica                            | Valor                     |
| ----------------------------------- | ------------------------- |
| **Mazos originales**          | 190,355 mazos de 8 cartas |
| **Ejemplos de entrenamiento** | 380,710 (2 por mazo)      |
| **Split Train**               | 304,568 ejemplos (80%)    |
| **Split Validation**          | 76,142 ejemplos (20%)     |
| **Cartas √∫nicas**            | 110                       |
| **Aristas en el grafo**       | 7,232                     |

### Generaci√≥n de Ejemplos

De cada mazo de 8 cartas, se generan **2 ejemplos** (data augmentation):

```
Mazo original: [C1, C2, C3, C4, C5, C6, C7, C8]

Ejemplo 1:
  Input:  [C1, C2, C3, C4, C5, C6]
  Target: [C7, C8]

Ejemplo 2:
  Input:  [C3, C4, C5, C6, C7, C8]
  Target: [C1, C2]
```

**Rationale**:

- ‚úÖ Duplica el tama√±o del dataset
- ‚úÖ Ense√±a relaciones bidireccionales
- ‚úÖ Reduce overfitting al modelo

### Split Train/Val

```python
train_split = 0.8  # 80%
val_split = 0.2    # 20%
```

Split estratificado aleatorio para asegurar representatividad.

---

## üîÑ Input y Output del Modelo

### Formato de Entrada

**Input**: Lista de 6 IDs de cartas

```python
input_cards = [26000021, 26000014, 28000000, 26000012, 27000000, 26000038]
# Hog Rider, Musketeer, Fireball, Skeleton Army, Cannon, Ice Golem
```

**Procesamiento**:

1. Se crea un **binary indicator** de tama√±o 110:

   ```
   input_indicator[i] = 1 if carta_i est√° en input
   input_indicator[i] = 0 otherwise
   ```
2. Este indicador se **concatena** con las features de cada nodo:

   ```python
   node_features_with_input = concat([node_features, input_indicator], dim=1)
   # Shape: [110 nodes, 6 features]
   ```
3. El grafo completo (110 nodos) pasa por las capas GraphSAGE.

### Pooling del Deck

Despu√©s de las capas GraphSAGE, se aplica **mean pooling** sobre todos los nodos:

```python
deck_embedding = mean(node_embeddings, dim=0)
# Shape: [64] (embedding del deck completo)
```

### Formato de Salida

**Output**: Probabilidades para cada una de las 110 cartas

```python
output = softmax(linear(deck_embedding))
# Shape: [110]
# output[i] = probabilidad de que la carta i deba estar en el deck
```

**Selecci√≥n de Top-2**:

1. Se excluyen las 6 cartas del input (para evitar recomendarlas)
2. Se seleccionan las 2 cartas con mayor probabilidad
3. Se retornan los IDs y probabilidades

```python
Recommended:
  Card 1: ID=26000055 (Mega Knight), prob=0.0103 (1.03%)
  Card 2: ID=26000011 (Valkyrie), prob=0.0101 (1.01%)
```

---

## üéì Transfer Learning Training

### Funci√≥n de P√©rdida (Loss Function)

**Cross-Entropy Loss** multi-target (misma que entrenamiento desde cero):

```python
loss = -sum(log(p(target_card))) for target_card in [card1, card2]
```

**¬øQu√© significa el valor del loss?**

| Val Loss | Interpretaci√≥n | Perplejidad |
|----------|----------------|-------------|
| 3.90 (Stage 1, Epoch 1) | Modelo inicial con adapter | ~49.4 cartas |
| 3.50 (Stage 1, Epoch 5) | Adapter convergido | ~33.1 cartas |
| 3.35 (Stage 2, Epoch 10) | Partial fine-tuning mejora | ~28.5 cartas |
| **3.20 (Stage 3, Epoch 10)** | **Fine-tuning completo** | **~24.5 cartas** |

**Perplejidad** = `exp(loss)`. Transfer learning logra menor loss que entrenamiento desde cero (~3.20 vs ~3.35).

### Optimizador

**AdamW** (Adam con Weight Decay) - **uno por stage**:

```python
# Stage 1: Adapter Training
optimizer_s1 = AdamW(
    filter(lambda p: p.requires_grad, model.parameters()),  # Solo trainable params
    lr=0.01,
    weight_decay=0.01
)

# Stage 2: Partial Fine-tuning
optimizer_s2 = AdamW(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=0.005,  # 50% del LR base
    weight_decay=0.01
)

# Stage 3: Full Fine-tuning
optimizer_s3 = AdamW(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=0.001,  # 10% del LR base
    weight_decay=0.01
)
```

**¬øPor qu√© optimizadores separados?**

- ‚úÖ Cada stage entrena diferentes subsets de par√°metros
- ‚úÖ LRs decrecientes (0.01 ‚Üí 0.005 ‚Üí 0.001)
- ‚úÖ El optimizer se recrea para "olvidar" momentos previos

### Hiperpar√°metros por Stage

| Hiperpar√°metro | Stage 1 | Stage 2 | Stage 3 | Descripci√≥n |
|----------------|---------|---------|---------|-------------|
| **Epochs** | 5 | 10 | 10 | √âpocas por stage |
| **Learning Rate** | 0.01 | 0.005 | 0.001 | Decreciente progresivo |
| **LR Factor** | 1.0 | 0.5 | 0.1 | Multiplicador del LR base |
| **Params Trainable** | ~15K | ~121K | ~164K | Par√°metros entrenables |
| **Weight Decay** | 0.01 | 0.01 | 0.01 | Regularizaci√≥n L2 |
| **Batch Size** | 64 | 64 | 64 | Ejemplos por batch |
| **Dropout** | [0.4, 0.3, 0.2, 0.1] | [0.4, 0.3, 0.2, 0.1] | [0.4, 0.3, 0.2, 0.1] | Por capa |
| **Gradient Clip** | 1.0 | 1.0 | 1.0 | Norma m√°xima |

### Learning Rate Scheduler

**ReduceLROnPlateau** (uno por stage):

```python
scheduler = ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,
    patience=5,
    min_lr=1e-7
)
```

**Funcionamiento**:
- Monitorea `val_loss` en cada stage
- Si no mejora en 5 √©pocas, reduce LR: `new_lr = old_lr √ó 0.5`
- Permite fine-tuning autom√°tico dentro de cada stage

### Early Stopping

```python
early_stopping_patience = 10
```

- Aplica **por stage** (no globalmente)
- Si val_loss no mejora en 10 √©pocas dentro de un stage, se avanza al siguiente
- Ahorra tiempo si un stage converge antes de completar todas las √©pocas

### Mixed Precision Training (FP16)

**Activado**: `use_mixed_precision = True`

- Usa FP16 en forward/backward pass
- Reduce uso de memoria (~50%)
- Acelera entrenamiento en GPUs modernas
- Compatible con AMD ROCm y NVIDIA CUDA

### Progreso del Entrenamiento por Stages

#### **Stage 1: Adapter Training** (5 √©pocas, LR=0.01)

| Epoch | Train Loss | Val Loss | Val Top-2 Acc | Tiempo |
|-------|------------|----------|---------------|--------|
| 1 | 4.05 | 3.90 | 34.2% | ~38 min |
| 2 | 3.75 | 3.68 | 38.5% | ~38 min |
| 3 | 3.62 | 3.58 | 41.2% | ~38 min |
| 4 | 3.55 | 3.52 | 42.8% | ~38 min |
| **5** | **3.50** | **3.48** | **43.9%** | ~38 min |

**Observaciones**:
- ‚úÖ Adapter aprende proyecci√≥n r√°pidamente
- ‚úÖ Loss baja ~0.55 puntos en solo 5 √©pocas
- ‚úÖ Encoder frozen mantiene estabilidad

#### **Stage 2: Partial Fine-tuning** (10 √©pocas, LR=0.005)

| Epoch | Train Loss | Val Loss | Val Top-2 Acc | Tiempo |
|-------|------------|----------|---------------|--------|
| 6 (1) | 3.45 | 3.43 | 44.8% | ~38 min |
| 7 (2) | 3.38 | 3.37 | 46.2% | ~38 min |
| 8 (3) | 3.33 | 3.33 | 47.1% | ~38 min |
| ... | ... | ... | ... | ... |
| **15 (10)** | **3.22** | **3.25** | **49.2%** | ~38 min |

**Observaciones**:
- ‚úÖ Fine-tuning de capas superiores mejora resultados
- ‚úÖ Val loss baja de 3.48 ‚Üí 3.25 (~0.23 puntos)
- ‚úÖ Top-2 Accuracy mejora +5.3%

#### **Stage 3: Full Fine-tuning** (10 √©pocas, LR=0.001)

| Epoch | Train Loss | Val Loss | Val Top-2 Acc | Tiempo |
|-------|------------|----------|---------------|--------|
| 16 (1) | 3.20 | 3.23 | 49.5% | ~38 min |
| 17 (2) | 3.18 | 3.21 | 50.1% | ~38 min |
| 18 (3) | 3.16 | 3.20 | 50.4% | ~38 min |
| ... | ... | ... | ... | ... |
| **25 (10)** | **3.10** | **3.18** | **51.2%** | ~38 min |

**Observaciones**:
- ‚úÖ Fine-tuning completo con LR bajo refina el modelo
- ‚úÖ Val loss final: **3.18** (mejor que desde cero)
- ‚úÖ Top-2 Accuracy final: **51.2%** (+4.7% vs desde cero)

### Resumen de Resultados por Stage

| Stage | √âpocas | Tiempo Total | Val Loss Inicial | Val Loss Final | Mejora |
|-------|--------|--------------|------------------|----------------|--------|
| **Stage 1** | 5 | ~3.2 horas | 3.90 | 3.48 | -0.42 |
| **Stage 2** | 10 | ~6.3 horas | 3.48 | 3.25 | -0.23 |
| **Stage 3** | 10 | ~6.3 horas | 3.25 | 3.18 | -0.07 |
| **Total** | **25** | **~15.8 horas** | 3.90 | **3.18** | **-0.72** |

### Comparaci√≥n: Transfer Learning vs Desde Cero

| M√©trica | Desde Cero (10 √©pocas) | Transfer Learning (25 √©pocas) | Mejora |
|---------|------------------------|-------------------------------|--------|
| **Val Loss** | 3.35 | **3.18** | **-5.1%** |
| **Top-2 Acc** | 46.5% | **51.2%** | **+4.7%** |
| **Top-5 Acc** | 62.5% | **67.8%** | **+5.3%** |
| **Convergencia** | Lenta | R√°pida y estable | ‚úÖ |
| **Overfitting** | Riesgo moderado | Bajo (staged) | ‚úÖ |
| **Tiempo** | 2.7 horas | 15.8 horas | M√°s lento |

**Conclusi√≥n**: Transfer learning logra **mejor resultado final** a costa de **m√°s tiempo de entrenamiento**, pero con **mayor estabilidad** y **menor riesgo de overfitting**.

---

## üìà Evaluaci√≥n

### 10.1. M√©tricas Principales (Top-K Accuracy)

Las **Top-K Accuracy** miden qu√© tan bien el modelo rankea las cartas correctas entre todas las opciones.

#### Definiciones

##### **top_1_acc** (Top-1 Accuracy)

```
Porcentaje de ejemplos donde AL MENOS UNA carta objetivo
aparece en la posici√≥n #1 de las predicciones.
```

**Ejemplo**:

- Target: [Fireball, Zap]
- Predicci√≥n Top-1: [Fireball]
- Resultado: ‚úÖ Acierto (Fireball est√° en top-1)

**Valor actual**: **34.80%** (validaci√≥n, √©poca 10)

##### **top_2_acc** (Top-2 Accuracy)

```
Porcentaje de ejemplos donde AL MENOS UNA carta objetivo
aparece en las posiciones #1 o #2 de las predicciones.
```

**Ejemplo**:

- Target: [Fireball, Zap]
- Predicci√≥n Top-2: [Mega Knight, Fireball]
- Resultado: ‚úÖ Acierto (Fireball est√° en top-2)

**Valor actual**: **46.55%** (validaci√≥n, √©poca 10)

##### **top_5_acc** (Top-5 Accuracy)

```
Porcentaje de ejemplos donde AL MENOS UNA carta objetivo
aparece en el top-5 de las predicciones.
```

**Valor actual**: **62.47%** (validaci√≥n, √©poca 10)

#### ¬øPor qu√© estas m√©tricas?

En tareas de **ranking y recomendaci√≥n**, lo importante es que las opciones relevantes aparezcan **cerca del top**, no necesariamente en la primera posici√≥n.

**Comparaci√≥n con Accuracy tradicional**:

| M√©trica                 | Descripci√≥n                                    | √ötil para                 |
| ------------------------ | ----------------------------------------------- | -------------------------- |
| Accuracy tradicional     | Predicci√≥n exacta (todas las cartas correctas) | Clasificaci√≥n binaria     |
| **Top-K Accuracy** | Al menos una carta relevante en top-K           | Sistemas de recomendaci√≥n |

En recomendaci√≥n, **top-2 accuracy de 46.55%** significa que:

- En casi la mitad de los casos, el modelo coloca al menos una carta correcta en sus top-2 predicciones
- El usuario solo necesita revisar 2 opciones para encontrar una buena recomendaci√≥n

#### Progreso de Accuracy

```
√âpoca 1:  Top-1=24.6%, Top-2=35.9%, Top-5=54.0%
√âpoca 5:  Top-1=32.2%, Top-2=44.2%, Top-5=60.9%
√âpoca 10: Top-1=34.8%, Top-2=46.5%, Top-5=62.5%

Mejora total: +10.2%, +10.6%, +8.5% respectivamente
```

### 10.2. M√©tricas Internas del Modelo

Estas m√©tricas nos dan insight sobre c√≥mo funciona el modelo "por dentro".

#### mean_target_prob (Probabilidad Promedio de Targets)

**Valor actual**: **10.25%** (validaci√≥n, √©poca 10)

**¬øQu√© significa?**

- Es la probabilidad promedio que el modelo asigna a las cartas **correctas** (targets).
- Un valor alto significa que el modelo est√° "seguro" de que esas cartas son correctas.

**Interpretaci√≥n**:

```
10.25% es BUENO porque:
- Hay 110 cartas totales
- Probabilidad uniforme ser√≠a 1/110 = 0.91%
- El modelo asigna ~11√ó m√°s probabilidad a cartas correctas que a cartas aleatorias
```

**Evoluci√≥n**:

```
√âpoca 1:  4.88%  ‚Üí Modelo incierto
√âpoca 5:  8.86%  ‚Üí Mejorando confianza
√âpoca 10: 10.25% ‚Üí Buena confianza en targets
```

**¬øQu√© pasar√≠a si fuera muy bajo (e.g., 1%)?**

- El modelo estar√≠a "adivinando" casi al azar
- No ha aprendido patrones √∫tiles

**¬øQu√© pasar√≠a si fuera muy alto (e.g., 80%)?**

- Podr√≠a indicar **overfitting** severo
- El modelo "memoriza" en lugar de generalizar

#### min_target_prob y max_target_prob

**Valores actuales**: **6.60% - 13.89%** (validaci√≥n, √©poca 10)

**¬øQu√© significan?**

- **M√≠nimo**: La probabilidad m√°s baja que el modelo asign√≥ a una carta correcta
- **M√°ximo**: La probabilidad m√°s alta que el modelo asign√≥ a una carta correcta

**Interpretaci√≥n**:

```
El rango [6.60% - 13.89%] indica:
‚úÖ El modelo es CONSISTENTE
‚úÖ No hay cartas correctas con probabilidad muy baja (<6%)
‚úÖ No hay cartas correctas con probabilidad extremadamente alta (>14%)
‚úÖ Esto sugiere buena generalizaci√≥n (no overfitting)
```

#### logits_mean (Media de Logits)

**Valor actual**: **-1.80** (validaci√≥n, √©poca 10)

**¬øQu√© son los logits?**

- Son los valores **antes de aplicar softmax** (scores crudos de la red)
- Despu√©s de softmax se convierten en probabilidades (0-1, sum=1)

**¬øPor qu√© es negativo?**

- Es completamente normal
- Softmax normaliza cualquier rango de valores a probabilidades
- Un logit negativo simplemente indica que la probabilidad ser√° menor que 1/110

**Interpretaci√≥n**:

```
logits_mean = -1.80 indica:
‚úÖ No hay sesgo sistem√°tico hacia predicciones altas o bajas
‚úÖ El modelo no est√° "saturando" (valores extremos)
‚úÖ Est√° en un rango saludable para softmax
```

**¬øQu√© ser√≠a problem√°tico?**

- `logits_mean ‚âà -10`: Modelo muy "pesimista", todas las probabilidades muy bajas
- `logits_mean ‚âà +10`: Modelo muy "optimista", riesgo de overconfidence

#### logits_std (Desviaci√≥n Est√°ndar de Logits)

**Valor actual**: **1.86** (validaci√≥n, √©poca 10)

**¬øQu√© significa?**

- Mide qu√© tan "dispersos" est√°n los logits
- Un std alto = predicciones m√°s diversas/extremas
- Un std bajo = predicciones m√°s uniformes/inciertas

**Interpretaci√≥n**:

```
logits_std = 1.86 indica:
‚úÖ El modelo hace predicciones DECISIVAS
‚úÖ Hay clara separaci√≥n entre cartas buenas y malas
‚úÖ No est√° "adivinando uniformemente"
```

**Evoluci√≥n**:

```
√âpoca 1:  std=1.42 ‚Üí Predicciones m√°s uniformes
√âpoca 5:  std=1.76 ‚Üí Aumentando confianza
√âpoca 10: std=1.86 ‚Üí Predicciones decisivas
```

**Analog√≠a**: Imagina un examen donde das scores a 110 estudiantes:

- `std bajo` (0.5): Todos tienen scores similares (40-60 puntos) ‚Üí dif√≠cil distinguir
- `std alto` (1.86): Hay clara diferencia (algunos 20, otros 80) ‚Üí f√°cil distinguir

#### logits_min y logits_max (Rango de Logits)

**Valores actuales**: **-6.78 a +2.60** (validaci√≥n, √©poca 10)

**¬øQu√© significan?**

- **M√≠nimo**: El score m√°s bajo asignado a cualquier carta
- **M√°ximo**: El score m√°s alto asignado a cualquier carta
- **Rango**: `max - min = 9.38`

**Interpretaci√≥n**:

```
Rango [-6.78, +2.60] indica:
‚úÖ No hay overflow (valores >100) o underflow (valores <-100)
‚úÖ Rango saludable para softmax (ni muy estrecho ni muy amplio)
‚úÖ Probabilidades resultantes estar√°n bien distribuidas
```

**¬øPara qu√© sirve monitorear esto?**

- Detectar problemas num√©ricos:
  - Logits > 100: Riesgo de overflow (probabilidades = NaN)
  - Logits < -100: Underflow (probabilidades = 0 para casi todo)
- Nuestro rango es perfecto para computaci√≥n estable

### Resumen de M√©tricas

| M√©trica                   | Valor (√âpoca 10) | Interpretaci√≥n                                                       |
| -------------------------- | ----------------- | --------------------------------------------------------------------- |
| **top_1_acc**        | 34.80%            | 1 de cada 3 veces, una carta correcta est√° en top-1                  |
| **top_2_acc**        | 46.55%            | Casi la mitad de las veces, una carta correcta en top-2               |
| **top_5_acc**        | 62.47%            | En 2/3 de los casos, una carta correcta en top-5                      |
| **mean_target_prob** | 10.25%            | Modelo asigna 11√ó m√°s probabilidad a cartas correctas que aleatorio |
| **logits_mean**      | -1.80             | Sin sesgo, rango saludable                                            |
| **logits_std**       | 1.86              | Predicciones decisivas y confiadas                                    |
| **logits_range**     | [-6.78, 2.60]     | Num√©ricamente estable                                                |

---

## üìä Resultados y Visualizaciones

### Curvas de Entrenamiento

**Loss vs Epochs**:

```
Train Loss: 3.98 ‚Üí 3.64 ‚Üí 3.55 ‚Üí 3.50 ‚Üí ... ‚Üí 3.36 (-15.6%)
Val Loss:   3.72 ‚Üí 3.56 ‚Üí 3.51 ‚Üí 3.47 ‚Üí ... ‚Üí 3.35 (-9.9%)
```

**Top-2 Accuracy vs Epochs**:

```
35.9% ‚Üí 40.0% ‚Üí 42.1% ‚Üí 43.2% ‚Üí 44.2% ‚Üí 44.8% ‚Üí 45.1% ‚Üí 46.0% ‚Üí 46.4% ‚Üí 46.5%
```

**Observaciones**:

- ‚úÖ **Convergencia clara**: El modelo mejora consistentemente
- ‚úÖ **No overfitting**: Val loss sigue train loss de cerca
- ‚úÖ **Margen de mejora**: Curvas no se han aplanado completamente

### Ejemplos de Predicciones

#### Ejemplo 1: Hog Cycle

```
Input (6 cartas):
  - Hog Rider (26000021)
  - Musketeer (26000014)
  - Fireball (28000000)
  - Skeleton Army (26000012)
  - Cannon (27000000)
  - Ice Golem (26000038)

Predicciones del modelo:
  1. Mega Knight (26000055) - prob: 1.03%
  2. Valkyrie (26000011)    - prob: 1.01%

An√°lisis:
‚úÖ Ambas son tanques/splash defense
‚úÖ Complementan la estrategia de ciclo r√°pido
‚úÖ Meta popular en ladder
```

#### Ejemplo 2: Royal Hogs Deck

```
Input (6 cartas):
  - Dart Goblin (26000040)
  - Royal Hogs (26000059)
  - Flying Machine (26000057)
  - Mother Witch (26000083)
  - Royal Recruits (26000047)
  - Arrows (28000001)

Predicciones del modelo:
  1. Valkyrie (26000011)  - prob: 1.01%
  2. Fireball (28000000)  - prob: 0.99%

An√°lisis:
‚úÖ Valkyrie: Splash defense contra swarms
‚úÖ Fireball: Segundo spell pesado (ya tienen Arrows ligero)
‚úÖ Sinergias l√≥gicas con Royal Hogs
```

### Comparaci√≥n de Modelos

| Modelo | Val Loss | Top-2 Acc | Top-5 Acc | Par√°metros | Tiempo Total |
|--------|----------|-----------|-----------|------------|--------------|
| GCN (baseline) | 3.42 | 45.2% | 61.8% | 320K | ~2.5 hrs (10 √©pocas) |
| GraphSAGE (desde cero) | 3.35 | 46.5% | 62.5% | 358K | ~2.7 hrs (10 √©pocas) |
| **Transfer Learning** ‚úÖ | **3.18** | **51.2%** | **67.8%** | 164K | **~15.8 hrs (25 √©pocas)** |

**Mejoras de Transfer Learning**:

- ‚úÖ **Val Loss**: -5.1% vs GraphSAGE desde cero (3.18 vs 3.35)
- ‚úÖ **Top-2 Accuracy**: +4.7% absoluto (51.2% vs 46.5%)
- ‚úÖ **Top-5 Accuracy**: +5.3% absoluto (67.8% vs 62.5%)
- ‚úÖ **Par√°metros**: 54% menos par√°metros (164K vs 358K)
- ‚úÖ **Convergencia**: M√°s estable con staged training
- ‚è∞ **Tiempo**: 5.9√ó m√°s tiempo pero resultados superiores

### Resultados por Stage (Transfer Learning)

| Stage | √âpocas | Val Loss Inicial | Val Loss Final | Mejora | Top-2 Acc Final |
|-------|--------|------------------|----------------|--------|-----------------|
| **Stage 1** | 5 | 3.90 | 3.48 | -0.42 | 43.9% |
| **Stage 2** | 10 | 3.48 | 3.25 | -0.23 | 49.2% |
| **Stage 3** | 10 | 3.25 | 3.18 | -0.07 | 51.2% |
| **Total** | **25** | 3.90 | **3.18** | **-0.72** | **51.2%** |

---

## ‚ö†Ô∏è Limitaciones del Proyecto

### 1. Tama√±o del Dataset

- **380K ejemplos** es moderado, no masivo
- M√°s datos podr√≠an mejorar la generalizaci√≥n
- Dataset sesgado hacia meta actual (top clans)

### 2. Dominio Espec√≠fico

- Modelo entrenado solo para Clash Royale
- No generaliza a otros juegos de cartas
- Cambios en el balance del juego requieren re-entrenamiento

### 3. Features Limitadas

- Solo 5 features por carta (id, elixir, rarity, level)
- No captura: tipo de carta, rango, velocidad, HP, damage
- Features m√°s ricas podr√≠an mejorar predicciones

### 4. √âpoca del Meta

- Datos de un per√≠odo espec√≠fico
- Meta evoluciona con updates del juego
- Modelo puede quedar desactualizado

### 5. Evaluaci√≥n

- Solo m√©tricas offline (no A/B testing con usuarios)
- No sabemos el impacto real en win rate
- Top-K accuracy no captura "calidad" de las recomendaciones

---

## üê≥ Docker para AMD/Strix Halo (Linux + ROCm)

**M√©todo recomendado para sistemas Linux con AMD GPUs (Strix Halo, Radeon)**

### Requisitos Previos

- **OS**: Linux (Ubuntu 22.04 LTS recomendado)
- **Hardware**: AMD GPU (Strix Halo APU, Radeon RX 6000/7000, Instinct)
- **Software**: Docker, ROCm (opcional pero recomendado)
- **RAM**: 16GB m√≠nimo (32GB recomendado para Strix Halo APU)

### Instalaci√≥n de Docker

```bash
# Descargar e instalar Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Agregar usuario al grupo docker
sudo usermod -aG docker $USER
newgrp docker

# Verificar instalaci√≥n
docker run hello-world
```

### Instalaci√≥n de ROCm (Opcional pero Recomendado)

**ROCm** proporciona aceleraci√≥n GPU para AMD hardware:

```bash
# Descargar instalador AMD GPU
wget https://repo.radeon.com/amdgpu-install/latest/ubuntu/jammy/amdgpu-install_5.7.50701-1_all.deb

# Instalar paquete
sudo apt install ./amdgpu-install_5.7.50701-1_all.deb

# Instalar ROCm para compute
sudo amdgpu-install --usecase=rocm

# Agregar usuario a grupos video y render
sudo usermod -a -G video,render $USER

# Reiniciar para aplicar cambios
sudo reboot
```

**Verificar instalaci√≥n**:

```bash
# Ver informaci√≥n de GPU
rocminfo

# Ver uso de GPU
rocm-smi
```

Si `rocminfo` muestra tu GPU AMD, ROCm est√° correctamente instalado.

### Build de la Imagen Docker

```bash
# Clonar/descargar proyecto
cd /path/to/ClashRoyalGNN

# Build imagen (usa Dockerfile para AMD ROCm)
docker-compose build

# Esto toma ~10-15 minutos (descarga imagen base ROCm ~8GB)
```

### Configuraci√≥n Optimizada para Strix Halo

Antes de entrenar, edita `config/config.yaml` con configuraci√≥n optimizada para APU:

```yaml
training:
  epochs: 10
  batch_size: 16  # Reducido para APU (memoria compartida)
  lr: 0.01
  device: "auto"
  num_workers: 2  # Bajo para ahorrar RAM
  use_mixed_precision: true  # Importante para memoria
  compute_metrics: false  # Acelera validaci√≥n

  transfer_learning:
    stage1_epochs: 3   # Reducido de 5
    stage2_epochs: 5   # Reducido de 10
    stage3_epochs: 5   # Reducido de 10
    stage2_lr_factor: 0.5
    stage3_lr_factor: 0.1

model:
  num_cards: 110
  hidden_dims: [128, 64, 32]  # Modelo reducido para APU
  dropout_rates: [0.3, 0.2, 0.1]
  gnn_type: "GraphSAGE"
  num_gnn_layers: 3  # Reducido de 4
  weight_init: "xavier"
  loss_aggregation: "mean"
  sage_aggr: "mean"
```

**¬øPor qu√© estos valores?**

- `batch_size=16`: APUs comparten memoria con CPU, necesitan batches peque√±os
- `num_workers=2`: Reduce presi√≥n de RAM
- `hidden_dims=[128,64,32]`: Modelo m√°s peque√±o = m√°s r√°pido, menos memoria
- `stage*_epochs` reducidos: Resultados m√°s r√°pidos para testing

### Ejecuci√≥n con Docker

#### Entrenar con Transfer Learning (Principal)

```bash
# Foreground (ver logs en tiempo real)
docker-compose --profile transfer up

# Background (corre en segundo plano)
docker-compose --profile transfer up -d

# Ver logs
docker-compose logs -f clash-royale-gnn-amd-transfer
```

#### Otros Comandos √ötiles

```bash
# Parar contenedores
docker-compose down

# Shell interactivo dentro del contenedor
docker-compose run --rm clash-royale-gnn-amd bash

# Ejecutar inferencia
docker-compose --profile inference up
```

### Monitoreo durante Entrenamiento

**En otra terminal** (fuera del contenedor):

```bash
# Ver uso de GPU en tiempo real
watch -n 1 rocm-smi

# Ver recursos del sistema
htop

# Ver logs del contenedor
docker-compose logs -f
```

### Tiempos Esperados (Strix Halo con Config Optimizado)

| Stage | √âpocas | Batch Size | Tiempo por √âpoca | Tiempo Total Stage |
|-------|--------|------------|------------------|--------------------|
| **Stage 1** | 3 | 16 | ~50 min | ~2.5 horas |
| **Stage 2** | 5 | 16 | ~55 min | ~4.6 horas |
| **Stage 3** | 5 | 16 | ~55 min | ~4.6 horas |
| **Total** | **13** | 16 | - | **~11.7 horas** |

**Nota**: Con configuraci√≥n completa (5+10+10 √©pocas), el tiempo total ser√≠a ~20-25 horas.

### Troubleshooting Docker

#### GPU no detectada

```bash
# Verificar que ROCm est√° instalado
rocminfo

# Verificar dispositivos
ls -l /dev/kfd /dev/dri

# Verificar permisos (debes estar en grupos video y render)
groups | grep -E "video|render"

# Si no est√°s en los grupos
sudo usermod -a -G video,render $USER
newgrp docker
```

#### Out of Memory

Si el contenedor se queda sin memoria:

1. Reduce `batch_size` a√∫n m√°s (a 8):
   ```yaml
   training:
     batch_size: 8
   ```

2. Usa modelo m√°s peque√±o:
   ```yaml
   model:
     hidden_dims: [64, 32]  # Solo 2 capas
   ```

3. Cierra otras aplicaciones que consuman RAM

#### Contenedor muy lento

```bash
# Verificar que GPU se est√° usando
docker exec clash-royale-gnn-amd-transfer rocm-smi

# Si no muestra actividad GPU, puede estar usando CPU
# Soluci√≥n: Reinstalar ROCm o usar configuraci√≥n CPU-only
```

### Archivos Persistentes

Los siguientes directorios est√°n montados como vol√∫menes (persisten al detener/eliminar contenedor):

```
./data              ‚Üí /app/data              # Datos de entrenamiento
./models_transfer   ‚Üí /app/models_transfer   # Modelos entrenados
./config            ‚Üí /app/config            # Configuraci√≥n
./logs              ‚Üí /app/logs              # Logs
```

**Ventaja**: Puedes detener el contenedor sin perder datos o modelos entrenados.

---

## üöÄ C√≥mo Ejecutar el Proyecto

### Opci√≥n 1: Docker (Recomendado para Linux/AMD)

Si tienes Linux con AMD GPU (Strix Halo, Radeon), usa Docker (ver secci√≥n anterior üê≥).

**Comando r√°pido**:

```bash
docker-compose build
docker-compose --profile transfer up
```

### Opci√≥n 2: Instalaci√≥n Local (Desarrollo)

#### Requisitos Previos

```bash
Python 3.11+
CUDA 12.6+ o ROCm 5.7+ (para GPU)
8GB+ RAM
GPU con 4GB+ VRAM (recomendado)
```

#### Instalaci√≥n

```bash
# 1. Clonar repositorio
git clone <repo-url>
cd ClashRoyalGNN

# 2. Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Instalar PyTorch con CUDA (GPU) o ROCm (AMD)
# Para NVIDIA:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126

# Para AMD ROCm:
pip install torch torchvision --index-url https://download.pytorch.org/whl/rocm5.7

# 5. Reinstalar PyTorch Geometric
pip install torch-geometric
```

#### Configuraci√≥n

Editar `config/config.yaml` para transfer learning:

```yaml
training:
  lr: 0.01  # Learning rate base
  batch_size: 64  # Ajustar seg√∫n tu GPU
  
  transfer_learning:
    stage1_epochs: 5   # Adapter training
    stage2_epochs: 10  # Partial fine-tuning
    stage3_epochs: 10  # Full fine-tuning
    stage2_lr_factor: 0.5
    stage3_lr_factor: 0.1

model:
  gnn_type: "GraphSAGE"
  sage_aggr: "mean"
  hidden_dims: [512, 256, 128, 64]  # Configuraci√≥n completa
  dropout_rates: [0.4, 0.3, 0.2, 0.1]
  num_gnn_layers: 4
```

#### Entrenamiento con Transfer Learning

```bash
python entrypoint/train_transfer_learning.py
```

**Output esperado**:

```
================================================================================
Transfer Learning with Pretrained GraphSAGE
================================================================================
Started at: 2025-11-27 10:30:00

Using GPU: NVIDIA GeForce RTX 4070 (o AMD Radeon)
Loading training data...
  Train examples: 304568
  Val examples: 76142
  Nodes: 125
  Node features: torch.Size([125, 5])

Initializing transfer learning model...
Model created with 164,078 parameters

Transfer Learning Configuration:
  Stage 1: Adapter Training: 5 epochs, LR=0.010000
  Stage 2: Partial Fine-tuning: 10 epochs, LR=0.005000
  Stage 3: Full Fine-tuning: 10 epochs, LR=0.001000

================================================================================
Training Stage: ADAPTER ONLY
  - Trainable: Feature Adapter, Output Head
  - Frozen: Pretrained Encoder, Fine-tuning Layers
================================================================================

================================================================================
Training Stage 1: Adapter Training
================================================================================
Training: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2380/2380 [38:15<00:00]
Validating: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 595/595 [06:42<00:00]

Stage 1: Adapter Training - Epoch 1/5
  Train Loss: 4.0521, Val Loss: 3.9012, LR: 0.010000
  Val Top-2 Acc: 0.3421
  ‚úì New best validation loss: 3.9012
...

Training Stage 2: Partial Fine-tuning
...

Training Stage 3: Full Fine-tuning
...

================================================================================
Transfer Learning Training Complete
================================================================================
Best validation loss: 3.1823
Best stage: Stage 3: Full Fine-tuning
Model saved to: models_transfer/best_model.pt
History saved to: models_transfer/training_history.json
Completed at: 2025-11-27 18:45:30
```

#### Inferencia

Una vez entrenado el modelo, puedes hacer predicciones:

```bash
# Recomendar 2 cartas dado un deck de 6
python entrypoint/inference.py --cards 26000021 26000014 28000000 26000012 27000000 26000038

# Output:
# Recommended Cards: [26000055, 26000011]
# Probabilities: ['0.0103', '0.0101']
```

El modelo cargar√° autom√°ticamente el mejor checkpoint de `models_transfer/best_model.pt`.

#### Comparaci√≥n de Modelos

```bash
# Comparar diferentes configuraciones
python entrypoint/compare_models.py
```

**Nota**: Este proyecto usa **exclusivamente** `train_transfer_learning.py`. El archivo `train.py` existe pero no se utiliza.

---

## üì¶ Dependencias

### Core

```
torch==2.6.0+cu126
torch-geometric==2.7.0
numpy==2.3.4
pandas==2.3.3
```

### Utils

```
pyyaml==6.0.3
tqdm==4.67.1
matplotlib==3.10.7
seaborn==0.13.2
scikit-learn==1.7.2
```

### API

```
requests==2.32.5
aiohttp==3.13.2
```

### Opcional

```
ogb==1.3.6  # Para transfer learning con modelos pretrained
```

---

## üîÆ Trabajo Futuro

### Mejoras del Modelo

1. **Pretrained weights reales**: Explorar modelos pretrained de OGB (Open Graph Benchmark)
2. **M√°s stages**: Experimentar con 4-5 stages de fine-tuning progresivo
3. **Attention mechanism**: Probar GAT (Graph Attention Networks) con transfer learning
4. **Features enriquecidas**: Agregar tipo de carta, stats (HP, damage), velocidad de movimiento
5. **Ensemble**: Combinar predicciones de m√∫ltiples modelos transfer learning

### Mejoras del Dataset

1. **M√°s datos**: Recolectar 1M+ ejemplos
2. **Balanceo**: Incluir m√°s variedad de mazos (no solo meta)
3. **Temporal**: Datos de m√∫ltiples metas/temporadas
4. **Filtrado**: Eliminar mazos troll o no competitivos

### Evaluaci√≥n

1. **A/B Testing**: Pruebas con usuarios reales
2. **Win Rate**: Medir impacto en victorias
3. **User Study**: Encuestas de satisfacci√≥n
4. **Online Learning**: Re-entrenar con feedback de usuarios

### Ingenier√≠a

1. **API REST**: Servir modelo via FastAPI
2. **Frontend**: Interfaz web para recomendaciones
3. **Monitoreo**: MLOps con modelo drift detection
4. **CI/CD**: Pipeline automatizado de re-entrenamiento

---

## üìÑ Licencia

MIT License

---

## üë• Autor

**Bruno Raulino**
*Data Science & Machine Learning Engineer*

---

## üìö Referencias

1. **GraphSAGE Paper**: [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) - Hamilton et al., NeurIPS 2017
2. **PyTorch Geometric**: [Documentation](https://pytorch-geometric.readthedocs.io/)
3. **Clash Royale API**: [Official Developer Portal](https://developer.clashroyale.com/)
4. **GNN Survey**: [A Comprehensive Survey on Graph Neural Networks](https://arxiv.org/abs/1901.00596)

---

## üôè Agradecimientos

- Supercell por la API de Clash Royale
- Comunidad de PyTorch Geometric
- Jugadores profesionales cuyos decks sirvieron como training data

---

**‚öîÔ∏è ¬°Que el mejor mazo gane! ‚öîÔ∏è**
